---
title: Quotes
parent: AI
nav_order: 1
---

The most beautiful idea in deep learning is that it actually works - [Ilya Sutskever](https://www.youtube.com/watch?v=13CZPWmke6A)

In 2015, when we said we are going for AGI, people thought we were batshit insane.  We don't get mocked as much now - [Sam Altman](https://www.youtube.com/watch?v=L_Guz73e6fw)

If coding became 10x more productive, we would have more code, rather than fewer programmers.  There's a supply issue - [Sam Altman](https://www.youtube.com/watch?v=L_Guz73e6fw)

Tasks—like writing essays—that we humans could do, but we didn’t think computers could do, are actually in some sense computationally easier than we thought - [Stephen Wolfram](https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/)

Deep learning equals getting something from applying scale.  What did people used to do with supercomputers? - [Ilya Sutskever](https://www.youtube.com/watch?v=SjhIlw3Iffs)

LLMs are like System 1 - [Andrej Karpathy](https://build.microsoft.com/en-US/sessions/db3f4859-cd30-4445-a0cd-553c3304f8e2)

We have to view this as a—potentially surprising—scientific discovery: that somehow in a neural net like ChatGPT’s it’s possible to capture the essence of what human brains manage to do in generating language - [Stephen Wolfram](https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/)

If I were a tester in a Turing Test, I feel like I wouldn’t have to wait for ChatGPT to come up with nonsense in order to decide it’s a computer. As someone put it in another thread, it’s way more “erudite” than a human. That is, even with the caveat that it doesn’t fundamentally understand what it’s saying, it can construct plausible, voluminous and often correct discourse on way more topics than a human ever could - [Chuckstar](https://arstechnica.com/information-technology/2023/06/researchers-discover-that-chatgpt-prefers-repeating-25-jokes-over-and-over/?comments=1&post=41939825)

Everyone grabs everything they can, they dump it in a huge file, and they kind of set it on fire to train some huge thing, and no one really knows yet what data in the pile actually matters - [David Holtz](https://www.theverge.com/2022/8/2/23287173/ai-image-generation-art-midjourney-multiverse-interview-david-holz)

GPT is now at the level of a somewhat confused maths undergraduate who doesn't really understand the material but has studied everything - [Terence Tao](https://www.youtube.com/watch?v=CGke7Q08hko)

With GPT questions, the vaguer the better sometimes - [Terence Tao](https://www.youtube.com/watch?v=CGke7Q08hko)

The thing about language models is the more I look at them, the more I think that they’re fractally interesting. Focus on any particular aspect, zoom in and there are just more questions, more unknowns and more interesting things to get into - [Simon Willison](https://simonwillison.net/2023/Aug/3/weird-world-of-llms/)